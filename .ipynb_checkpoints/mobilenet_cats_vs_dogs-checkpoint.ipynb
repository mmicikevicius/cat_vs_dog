{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import imghdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained MobileNet model load with custom configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "base_model=keras.applications.MobileNet(input_shape = (64,64,3), include_top=False, weights='imagenet', classes=1000) #imports the MobileNetV2 model and discards the last 1000 neuron layer.\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(128,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(128,activation='relu')(x) #dense layer 2\n",
    "preds=Dense(3,activation='softmax')(x) #final layer with softmax activation for 3 classes\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds) #specify the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8452 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale = 1./255,\n",
    "                                 rotation_range = 270)\n",
    "train_generator=train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2113 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "265/265 [==============================] - 93s 342ms/step - loss: 0.7157 - accuracy: 0.6757 - val_loss: 0.6128 - val_accuracy: 0.7354\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 103s 389ms/step - loss: 0.4854 - accuracy: 0.7831 - val_loss: 0.6690 - val_accuracy: 0.6876\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 105s 397ms/step - loss: 0.4374 - accuracy: 0.8081 - val_loss: 0.8423 - val_accuracy: 0.6555\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 104s 391ms/step - loss: 0.4224 - accuracy: 0.8159 - val_loss: 0.7562 - val_accuracy: 0.6910\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 102s 384ms/step - loss: 0.3789 - accuracy: 0.8419 - val_loss: 0.5011 - val_accuracy: 0.7903\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 101s 382ms/step - loss: 0.3529 - accuracy: 0.8526 - val_loss: 0.4339 - val_accuracy: 0.8140\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 103s 388ms/step - loss: 0.3378 - accuracy: 0.8534 - val_loss: 0.8360 - val_accuracy: 0.7165\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 103s 387ms/step - loss: 0.3295 - accuracy: 0.8589 - val_loss: 2.0756 - val_accuracy: 0.4761\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 102s 384ms/step - loss: 0.3179 - accuracy: 0.8687 - val_loss: 0.3693 - val_accuracy: 0.8443\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 102s 384ms/step - loss: 0.3143 - accuracy: 0.8601 - val_loss: 0.5083 - val_accuracy: 0.7903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbba3957be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x = train_generator, validation_data = test_generator, epochs = 10)\n",
    "#model.save('saved_model/mobilenetv2_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/mobilenet_model_v1/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('saved_model/mobilenet_model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_dog_prediction(directory = 'dataset/single_prediction'):\n",
    "    rows = []\n",
    "    for f in os.listdir(directory):\n",
    "        file_type = imghdr.what(directory + '/' + f)\n",
    "        if file_type in ('png', 'jpeg'):\n",
    "            test_image = image.load_img(directory + '/' + f, target_size = (64, 64))\n",
    "            test_image = image.img_to_array(test_image)\n",
    "            test_image = np.expand_dims(test_image, axis = 0)\n",
    "            result = model.predict(test_image)\n",
    "            result = np.argmax(result, axis=1)\n",
    "#            training_set.class_indices\n",
    "            if result[0] == 0:\n",
    "                prediction = 'cat'\n",
    "            elif result[0] == 1:\n",
    "                prediction = 'dog'\n",
    "            else:\n",
    "                prediction = 'unknown_class'\n",
    "        else:\n",
    "            prediction = 'unsupported_file'\n",
    "        rows.append([f, prediction])\n",
    "    results_table = pd.DataFrame(rows, columns=[\"Image Name\", \"Prediction\"])\n",
    "    print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
